# robots.txt for SkinVaults
# Generated and merged to allow search engines and AI crawlers while protecting sensitive routes

# Specific Search Engine Crawlers
User-agent: Googlebot
User-agent: googlebot-image
User-agent: googlebot-mobile
User-agent: bingbot
User-agent: MSNBot
User-agent: Slurp
User-agent: Gigabot
User-agent: Robozilla
User-agent: Nutch
User-agent: ia_archiver
User-agent: baiduspider
User-agent: naverbot
User-agent: yeti
User-agent: yahoo-mmcrawler
User-agent: psbot
User-agent: yahoo-blogs/v3.9
Disallow: /admin
Disallow: /api/
Disallow: /payment/
Disallow: /chat
Disallow: /notifications
Disallow: /fix-purchase

# Explicitly Allow AI/LLM Crawlers
User-agent: GPTBot
User-agent: ChatGPT-User
User-agent: CCBot
User-agent: anthropic-ai
User-agent: ClaudeBot
User-agent: PerplexityBot
User-agent: Google-Extended
User-agent: Applebot-Extended
User-agent: FacebookBot
Allow: /

# General Rules for All Other Bots
User-agent: *
Allow: /
Disallow: /admin
Disallow: /api/
Disallow: /payment/
Disallow: /chat
Disallow: /notifications
Disallow: /fix-purchase

# Crawl delay to prevent server overload
Crawl-delay: 1

# Sitemap and AI Documentation
Sitemap: https://www.skinvaults.online/sitemap.xml
# AI crawlers should read this file for site understanding
# Reference: https://llmstxt.org/
# Location: https://skinvaults.online/llms.txt