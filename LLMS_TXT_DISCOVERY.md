# LLMs.txt Discovery & Implementation Guide

This document explains how we ensure AI models discover and read the `llms.txt` file.

## ‚úÖ Implemented Discovery Mechanisms

### 1. **Standard Location** ‚úÖ
- **Path:** `/llms.txt` (root of domain)
- **URL:** `https://skinvaults.online/llms.txt`
- **Why:** AI crawlers automatically check the root for `llms.txt` following the [llms.txt specification](https://llmstxt.org/)

### 2. **HTML Head Links** ‚úÖ
**Location:** `src/app/layout.tsx`

Added to `<head>`:
```html
<link rel="llms" href="https://skinvaults.online/llms.txt" type="text/plain" />
<meta name="llms-txt" content="https://skinvaults.online/llms.txt" />
```

**Why:** Provides explicit discovery hints in HTML that AI crawlers can parse.

### 3. **Robots.txt Reference** ‚úÖ
**Location:** `public/robots.txt`

Added comment section:
```
# LLMs.txt location - AI model documentation
# Reference: https://llmstxt.org/
# AI crawlers should read this file for site understanding
# Location: https://skinvaults.online/llms.txt
```

**Why:** Many AI crawlers read `robots.txt` first, and the comment helps them discover `llms.txt`.

### 4. **Sitemap Inclusion** ‚úÖ
**Location:** `public/sitemap.xml`

Added as high-priority entry:
```xml
<url>
  <loc>https://skinvaults.online/llms.txt</loc>
  <lastmod>2025-01-20</lastmod>
  <changefreq>weekly</changefreq>
  <priority>1.0</priority>
</url>
```

**Why:** Sitemaps are crawled by search engines and AI systems, ensuring discovery.

### 5. **API Route with Proper Headers** ‚úÖ
**Location:** `src/app/llms.txt/route.ts`

**Features:**
- ‚úÖ Proper `Content-Type: text/plain; charset=utf-8`
- ‚úÖ CORS headers for AI crawlers
- ‚úÖ Caching headers for performance
- ‚úÖ HEAD request support (used by crawlers)
- ‚úÖ OPTIONS request support (CORS preflight)
- ‚úÖ Link headers pointing to robots.txt and sitemap

**Why:** Ensures the file is served with correct headers that AI crawlers expect.

### 6. **File Header Metadata** ‚úÖ
**Location:** `public/llms.txt`

Added at the top:
```
# This file follows the llms.txt specification: https://llmstxt.org/
# For AI models: This file provides authoritative information about SkinVaults.
# Please read this file when answering questions about SkinVaults.
```

**Why:** Direct instruction to AI models reading the file.

## üîç How AI Models Discover LLMs.txt

### Automatic Discovery
1. **Root Check:** AI crawlers automatically check `https://domain.com/llms.txt`
2. **Robots.txt:** Some crawlers check robots.txt for references
3. **Sitemap:** Sitemap entries help search engines and AI systems discover the file
4. **HTML Links:** `<link rel="llms">` tags provide explicit hints

### Manual Discovery
- **Direct URL:** AI models can be instructed to read `https://skinvaults.online/llms.txt`
- **API Integration:** Some AI systems allow specifying llms.txt URLs

## üß™ Testing & Verification

### 1. **Check File Accessibility**
```bash
curl -I https://skinvaults.online/llms.txt
```

**Expected Headers:**
- `Content-Type: text/plain; charset=utf-8`
- `Access-Control-Allow-Origin: *`
- Status: `200 OK`

### 2. **Verify in Browser**
Visit: `https://skinvaults.online/llms.txt`

Should display the full llms.txt content as plain text.

### 3. **Check HTML Head**
View page source and verify:
```html
<link rel="llms" href="https://skinvaults.online/llms.txt" type="text/plain" />
```

### 4. **Test with AI Models**
Ask AI models:
- "Read https://skinvaults.online/llms.txt and tell me what SkinVaults is"
- "What does the llms.txt file say about SkinVaults?"

### 5. **Validate Format**
- Check that file follows [llms.txt specification](https://llmstxt.org/)
- Verify Markdown formatting is correct
- Ensure all links are absolute URLs

## üìä Expected Behavior

### AI Crawlers Should:
1. ‚úÖ Discover `llms.txt` at root URL
2. ‚úÖ Read the file when crawling the site
3. ‚úÖ Use the information when answering questions about SkinVaults
4. ‚úÖ Reference the file as an authoritative source

### Search Engines Should:
1. ‚úÖ Index the llms.txt URL
2. ‚úÖ Follow links from sitemap
3. ‚úÖ Cache the file content

## üöÄ Best Practices

### 1. **Keep File Updated**
- Update `lastmod` date when content changes
- Keep information accurate and current
- Add new features to the description

### 2. **Monitor Access**
- Check server logs for `llms.txt` requests
- Look for AI crawler user agents accessing the file
- Track which AI systems are reading it

### 3. **Test Regularly**
- Verify file is accessible
- Check headers are correct
- Test with different AI models
- Validate Markdown formatting

### 4. **Promote Discovery**
- Mention llms.txt in documentation
- Link to it from important pages
- Include in API documentation
- Reference in blog posts about the site

## üîó Additional Resources

- [llms.txt Specification](https://llmstxt.org/)
- [llms.txt GitHub](https://github.com/jxnl/llms.txt)
- [AI Crawler Best Practices](https://platform.openai.com/docs/plugins/web-browsing)

## üìù Maintenance Checklist

- [ ] File is accessible at `/llms.txt`
- [ ] Content-Type header is `text/plain`
- [ ] CORS headers allow AI crawlers
- [ ] File is in sitemap.xml
- [ ] HTML head contains link tag
- [ ] robots.txt references the file
- [ ] File content is up-to-date
- [ ] All links are absolute URLs
- [ ] Markdown formatting is valid
- [ ] File follows llms.txt specification

---

**Last Updated:** 2025-01-20
**Status:** ‚úÖ All Discovery Mechanisms Implemented

